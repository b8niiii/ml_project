    "All three classes are close to ~\u2153 each.\n",
    "This means no strong class imbalance problem \u2192 the model won\u2019t be biased heavily toward one class.\n",
    "There are a few more \u201cscissors\u201d images than the others (38 more than paper).\n",
      "All images confirmed: PNG, RGB, 300\u00d7200.\n"
    "    print(\"All images confirmed: PNG, RGB, 300\u00d7200.\")"
      "Saved \u2192 data/processed/: train=1530, val=329, test=329\n"
    "print(f\"Saved \u2192 data/processed/: train={n_tr}, val={n_va}, test={n_te}\")"
    "Normalization - What \u201cnormalization\u201d does\n",
    "Why it helps: gradients don\u2019t explode/vanish as easily, learning rates behave more predictably, and pretrained initializations (if you use them later) expect normalized inputs."
    "Resizes them (default 128\u00d7128).\n",
    "Normalizes pixel values from [0,255] \u2192 [0,1] (needed for neural nets).\n",
    "train_ds \u2192 training set (with augmentation).\n",
    "val_ds \u2192 validation set (no augmentation, deterministic).\n",
    "test_ds \u2192 test set (no augmentation, deterministic).\n",
    "Prints the pixel range (should be 0.0 \u2192 1.0 after normalization).\n",
    "# PREP 3 \u2014 tf.data pipelines with normalization (and optional augmentation)\n",
    "    # Step 2. Normalize pixel values from [0,255] \u2192 [0,1] (float32)\n",
    "    wd = 1e-5\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    wd = 1e-5\n",
    "        x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
}